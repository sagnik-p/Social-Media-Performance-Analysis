{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# The SuperMind Hackathon\n",
    "\n",
    "\n",
    "## Sagnik Pramanik\n",
    "##### sagnikpramanik95@gmail.com"
   ],
   "id": "dc3fcf5486a58fb8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Importing everything we need: langchain components and astradb handler, utils such as os, dotenv and csv for reading csv files",
   "id": "ce4698a8cd2699bc"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-05T16:28:37.029999Z",
     "start_time": "2025-01-05T16:28:37.022246Z"
    }
   },
   "source": [
    "import os\n",
    "import csv\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from astrapy import DataAPIClient\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough"
   ],
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load the env variables and declare the dataset path",
   "id": "c20da885e984ab10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T16:28:37.512212Z",
     "start_time": "2025-01-05T16:28:37.507823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Retrieve Astra DB credentials and settings from environment variables\n",
    "ASTRA_TOKEN = os.getenv(\"ASTRA_TOKEN\")\n",
    "ASTRA_DB_URL = os.getenv(\"ASTRA_DB_URL\")\n",
    "COLLECTION_NAME = os.getenv(\"COLLECTION_NAME\")\n",
    "file_path=\"./dataset1.csv\""
   ],
   "id": "19428833e6fcc6f1",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, we connect to the DB\n",
   "id": "b6e9f146910ad4ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T16:28:37.813439Z",
     "start_time": "2025-01-05T16:28:37.792316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = DataAPIClient(ASTRA_TOKEN)\n",
    "db = client.get_database_by_api_endpoint(ASTRA_DB_URL)"
   ],
   "id": "af730672f4fb9bac",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creating a new collection if it does not exist already",
   "id": "ab662c42dcbea8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T16:28:54.093310Z",
     "start_time": "2025-01-05T16:28:38.072793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if COLLECTION_NAME not in db.list_collection_names():\n",
    "    db.create_collection(COLLECTION_NAME)\n",
    "    print(\"Created Collection\")\n",
    "else:\n",
    "    print(\"Collection already exists\")"
   ],
   "id": "8b112b0bce0a5fb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Collection\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, we read the rows from the dataset and then feed it to the database one by one",
   "id": "3464ce0e770eabb3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T16:29:00.980024Z",
     "start_time": "2025-01-05T16:28:57.666630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "collection = db.get_collection(COLLECTION_NAME)\n",
    "try:\n",
    "    with open(file_path, mode='r') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        c=1\n",
    "        for row in csv_reader:\n",
    "            # Prepare document to insert into the collection\n",
    "            document = {\n",
    "                \"post_id\": row[\"post_id\"],\n",
    "                \"day_of_posting\": row[\"day_of_posting\"],\n",
    "                \"date_of_posting\": row[\"date_of_posting\"],\n",
    "                \"time_of_posting\": row[\"time_of_posting\"],\n",
    "                \"post_type\": row[\"post_type\"],\n",
    "                \"likes\": int(row[\"likes\"]),\n",
    "                \"comments\": int(row[\"comments\"]),\n",
    "                \"shares\": int(row[\"shares\"]),\n",
    "                \"repost\": int(row[\"repost\"]),\n",
    "                \"gender\": row[\"gender\"],\n",
    "                \"hashtags\": row[\"hashtags\"].split(\",\") if row[\"hashtags\"].strip() else []\n",
    "            }\n",
    "\n",
    "            # Insert into the collection\n",
    "            collection.insert_one(document)\n",
    "            print(\"Processed row {}\".format(c))\n",
    "            c+=1\n",
    "\n",
    "        print(\"Data successfully inserted into the database.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{file_path}' not found.\")\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Missing required column in the file: {e}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error: Invalid data format: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ],
   "id": "151eb6e50e67ff8c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed row 1\n",
      "Processed row 2\n",
      "Processed row 3\n",
      "Processed row 4\n",
      "Processed row 5\n",
      "Processed row 6\n",
      "Processed row 7\n",
      "Processed row 8\n",
      "Processed row 9\n",
      "Processed row 10\n",
      "Data successfully inserted into the database.\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Lets check what is inside the DB",
   "id": "3f1067944fcc1271"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T16:29:05.679344Z",
     "start_time": "2025-01-05T16:29:05.375952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    data = collection.find()\n",
    "    data= [doc for doc in data]\n",
    "    print(data)\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving data from Astra DB: {e}\")"
   ],
   "id": "98e47be83b1367b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': '31f8d89a-e627-4f98-b8d8-9ae6275f98a1', 'post_id': '0000000000000009', 'day_of_posting': 'Tuesday', 'date_of_posting': '2024-12-23', 'time_of_posting': '14:00:00', 'post_type': 'video-carousel', 'likes': 225, 'comments': 48, 'shares': 25, 'repost': 13, 'gender': 'M', 'hashtags': ['#Music']}, {'_id': 'beb4915a-9e8f-4de7-b491-5a9e8fbde732', 'post_id': '0000000000000010', 'day_of_posting': 'Wednesday', 'date_of_posting': '2024-12-22', 'time_of_posting': '10:00:00', 'post_type': 'mixed-carousel', 'likes': 140, 'comments': 30, 'shares': 16, 'repost': 8, 'gender': 'F', 'hashtags': ['#Nature']}, {'_id': 'ff234ed9-b6e5-4b3a-a34e-d9b6e53b3aab', 'post_id': '0000000000000007', 'day_of_posting': 'Sunday', 'date_of_posting': '2024-12-25', 'time_of_posting': '13:30:00', 'post_type': 'reels', 'likes': 300, 'comments': 68, 'shares': 39, 'repost': 23, 'gender': 'M', 'hashtags': ['#Food']}, {'_id': '3b5beb3b-1005-4798-9beb-3b1005179868', 'post_id': '0000000000000002', 'day_of_posting': 'Tuesday', 'date_of_posting': '2024-12-30', 'time_of_posting': '14:15:00', 'post_type': 'reels', 'likes': 270, 'comments': 62, 'shares': 34, 'repost': 19, 'gender': 'F', 'hashtags': ['#ML']}, {'_id': 'd67a986a-6a92-44b4-ba98-6a6a9284b44f', 'post_id': '0000000000000003', 'day_of_posting': 'Wednesday', 'date_of_posting': '2024-12-29', 'time_of_posting': '12:00:00', 'post_type': 'static-images', 'likes': 65, 'comments': 17, 'shares': 8, 'repost': 3, 'gender': 'M', 'hashtags': []}, {'_id': '88ff27ff-f25d-4407-bf27-fff25d340774', 'post_id': '0000000000000006', 'day_of_posting': 'Saturday', 'date_of_posting': '2024-12-26', 'time_of_posting': '16:00:00', 'post_type': 'carousel', 'likes': 110, 'comments': 24, 'shares': 12, 'repost': 6, 'gender': 'F', 'hashtags': ['#Fashion']}, {'_id': '9d1c9f4f-4229-4bdc-9c9f-4f42292bdcf0', 'post_id': '0000000000000001', 'day_of_posting': 'Monday', 'date_of_posting': '2024-12-31', 'time_of_posting': '10:30:00', 'post_type': 'carousel', 'likes': 130, 'comments': 28, 'shares': 14, 'repost': 7, 'gender': 'M', 'hashtags': ['#Tech']}, {'_id': '253b492e-17df-4916-bb49-2e17dfe916a3', 'post_id': '0000000000000004', 'day_of_posting': 'Thursday', 'date_of_posting': '2024-12-28', 'time_of_posting': '09:00:00', 'post_type': 'video-carousel', 'likes': 195, 'comments': 43, 'shares': 22, 'repost': 11, 'gender': 'F', 'hashtags': ['#Fitness']}, {'_id': 'e1548ac8-3769-4dcf-948a-c83769bdcf54', 'post_id': '0000000000000008', 'day_of_posting': 'Monday', 'date_of_posting': '2024-12-24', 'time_of_posting': '08:00:00', 'post_type': 'static-images', 'likes': 60, 'comments': 14, 'shares': 7, 'repost': 2, 'gender': 'F', 'hashtags': []}, {'_id': '65f13a60-5f95-43c4-b13a-605f95a3c4e9', 'post_id': '0000000000000005', 'day_of_posting': 'Friday', 'date_of_posting': '2024-12-27', 'time_of_posting': '11:45:00', 'post_type': 'mixed-carousel', 'likes': 150, 'comments': 33, 'shares': 17, 'repost': 9, 'gender': 'M', 'hashtags': ['#Tech']}]\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Option 1: OpenAI",
   "id": "b52faca04b803439"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T16:29:07.292617Z",
     "start_time": "2025-01-05T16:29:07.244251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\",openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "prompt_template = (\n",
    "    \"Here is the entire dataset: {data}.\"\n",
    "    \"Summarize the key trends, patterns only without providing row-by-row details.\"\n",
    "    \"For example, One trend could be 'Posts by females receive 46% more likes compared to posts by male'. Similarly generate more insights from the data and use Numbers\"\n",
    "    \"Finally, the output should be a list of trends/insights. do not self genererate anything else and no suggestions.\"\n",
    "    \"Generate as many trends as possible, using all columns of the data\"\n",
    ")\n",
    "prompt = PromptTemplate(input_variables=[\"data\"], template=prompt_template)\n",
    "chain = (\n",
    "    {\"data\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ],
   "id": "e2ebb76dcd11aaab",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Option 2: Google Gemini",
   "id": "ee968c133ac45637"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T16:30:40.106329Z",
     "start_time": "2025-01-05T16:30:40.058049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "prompt_template = (\n",
    "    \"Here is the entire dataset: {data}. \"\n",
    "    \"Identify patterns, trends, and insights from this dataset. \"\n",
    "    \"Summarize the key trends only without providing row-by-row details.\"\n",
    "    \"For example, One trend could be 'Posts by females receive 46% more likes compared to posts by male'. similarly generate more insights from the data and use Numbers to further strengthen the trends.\"\n",
    "    \"Finally, the output should be a list of trends and insights from the data. do not genererate anything else, no suggestions.\"\n",
    "    \"Generate as many trends as possible, including all columns of the data, except the _id and post_id.\"\n",
    "    \"One of the trends could be to show the correlation between posts at different times and the engagement\"\n",
    ")\n",
    "prompt = PromptTemplate(input_variables=[\"data\"], template=prompt_template)\n",
    "chain = (\n",
    "    {\"data\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "id": "ba88344e98e1c144",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-05T16:30:48.836985Z",
     "start_time": "2025-01-05T16:30:40.715567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trends = chain.invoke(str(data))\n",
    "print(trends)"
   ],
   "id": "1a5cc33e67402f5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Reels and video carousels receive significantly more likes (average 247.5) than other post types (average 116).\n",
      "* Tuesday and Wednesday show higher average engagement (likes, comments, shares) compared to other days.\n",
      "* Posts made between 10:00 AM and 14:15 PM tend to receive more engagement than posts made outside this time frame.\n",
      "* Posts with hashtags receive substantially more engagement (average likes 193) than posts without hashtags (average likes 62.5).\n",
      "* Male and female posts show similar levels of engagement, with no significant difference in average likes, comments, or shares.\n",
      "*  There is a strong positive correlation between likes, comments, shares, and reposts; higher likes generally indicate higher comments, shares, and reposts.\n",
      "* '#Tech' and '#Food' hashtags show higher average engagement than other hashtags.\n",
      "* 'Mixed-carousel' and 'video-carousel' post types receive slightly higher average shares compared to other post types.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8b9ff0c75566828b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
